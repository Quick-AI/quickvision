{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quantization_Aware_Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Szb8iNNW1T"
      },
      "source": [
        "# Quantization Aware Training with Quickvision "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "284CKdbmNmwY"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import torch.quantization\n",
        "from torch.quantization import convert\n",
        "from torch.quantization import QuantStub, DeQuantStub"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA1vGYrROFf6"
      },
      "source": [
        "## Install Quickvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u47wjNirOHbd"
      },
      "source": [
        "! pip install -q git+https://github.com/Quick-AI/quickvision.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSqljABcOFJY"
      },
      "source": [
        "from quickvision.models.classification import cnn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlWOay9VOfpC"
      },
      "source": [
        "## Create CIFAR10 Dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3vOZRG1J7_t"
      },
      "source": [
        "train_transforms = T.Compose([T.ToTensor(), T.Normalize((0.5,), (0.5,))])\n",
        "valid_transforms = T.Compose([T.ToTensor(), T.Normalize((0.5,), (0.5,))])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfLY-Ow6NWh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1eda126-a4b3-443a-8fec-78876f4b68f6"
      },
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(\"./data\", download=True, train=True, transform=train_transforms)\n",
        "valid_dataset = torchvision.datasets.CIFAR10(\"./data\", download=True, train=False, transform=valid_transforms)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgA7bqckLJ4S"
      },
      "source": [
        "TRAIN_BATCH_SIZE = 512  # Training Batch Size\n",
        "VALID_BATCH_SIZE = 512  # Validation Batch Size"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDrXW2hRMe6o"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, TRAIN_BATCH_SIZE, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, VALID_BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2-sjNpCOn9y"
      },
      "source": [
        "## Create Quantization Aware Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFnjBOK7Je2w"
      },
      "source": [
        "qat_model = cnn.create_vision_cnn(\"mobilenet_v2\", pretrained=\"imagenet\", num_classes=10)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdmBKH5QNpbz"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(qat_model.parameters(), lr=1e-3)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJBvbLz0PWNI"
      },
      "source": [
        "## Set Quantization Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb_q01e_NrK4"
      },
      "source": [
        " qat_model.config = torch.quantization.get_default_qat_qconfig(\"fbgemm\")\n",
        "_ = torch.quantization.prepare_qat(qat_model, inplace=True)\n",
        "\n",
        "# We can fine-tune / train the qat_models on GPU too.\n",
        "\n",
        "for param in qat_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_ = qat_model.to(device)\n",
        "\n",
        "NUM_TRAIN_BATCHES = 5 # You can pass these too in train step if you want small subset to train\n",
        "NUM_VAL_BATCHES = 5  # You can pass these too in train step if you want small subset to validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYpwpNxgPaPo"
      },
      "source": [
        "## Train with Quickvision !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRAHFNgMPZ36"
      },
      "source": [
        "history = cnn.fit(epochs=3, model=qat_model, train_loader=train_loader,\n",
        "                    val_loader=valid_loader, criterion=criterion, device=device,\n",
        "                    optimizer=optimizer)\n",
        "\n",
        "qat_model.cpu()  # We need to move to cpu for conversion.\n",
        "\n",
        "qat_model_trained = torch.quantization.convert(qat_model, inplace=False)\n",
        "print(\"Converted the Quantization aware training model.\")\n",
        "# torch.save(model_quantized_and_trained.state_dict(), config.QAT_SAVE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0kYoDC9LjFc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}